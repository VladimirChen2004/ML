{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12003447,"sourceType":"datasetVersion","datasetId":7550997}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"3a564d5f","cell_type":"markdown","source":"#  –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ —á–∞—Ç-–±–æ—Ç–∞ —Å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π ü§ó Transformers\n\n__–ê–≤—Ç–æ—Ä –∑–∞–¥–∞—á: –ë–ª–æ—Ö–∏–Ω –ù.–í. (NVBlokhin@fa.ru)__\n\n–ú–∞—Ç–µ—Ä–∏–∞–ª—ã:\n* https://huggingface.co/docs/transformers/generation_strategies\n* https://huggingface.co/docs/transformers/main/tasks/prompting\n* https://huggingface.co/docs/huggingface_hub/guides/inference\n* https://huggingface.co/settings/tokens\n* https://huggingface.co/tiiuae/falcon-7b-instruct\n* https://python.langchain.com/\n* https://www.youtube.com/watch?v=cKjh5ZOWqus\n* https://docs.chainlit.io/get-started/overview\n* https://www.youtube.com/watch?v=cKjh5ZOWqus","metadata":{"id":"3a564d5f"}},{"id":"c9ecd663","cell_type":"markdown","source":"## –ó–∞–¥–∞—á–∏ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–Ω–æ–≥–æ —Ä–∞–∑–±–æ—Ä–∞","metadata":{"id":"c9ecd663"}},{"id":"1a9f47a1","cell_type":"markdown","source":"1\\. –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —Ä–∞–±–æ—Ç—É —Å –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ –∏–∑ ü§ó Transformers –ø—Ä–∏ –ø–æ–º–æ—â–∏ Inference API","metadata":{"id":"1a9f47a1"}},{"id":"6_PwG0r9EqU_","cell_type":"code","source":"!pip install python-dotenv","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6_PwG0r9EqU_","executionInfo":{"status":"ok","timestamp":1746190646013,"user_tz":-180,"elapsed":3833,"user":{"displayName":"–ù–∏–∫–∏—Ç–∞ –ë–ª–æ—Ö–∏–Ω","userId":"16402972581398673009"}},"outputId":"dfb080fa-c334-4c12-a608-4e213ab1fa78","trusted":true,"execution":{"iopub.status.busy":"2025-05-29T22:31:12.995250Z","iopub.execute_input":"2025-05-29T22:31:12.995554Z","iopub.status.idle":"2025-05-29T22:31:16.955892Z","shell.execute_reply.started":"2025-05-29T22:31:12.995531Z","shell.execute_reply":"2025-05-29T22:31:16.955183Z"}},"outputs":[{"name":"stdout","text":"Collecting python-dotenv\n  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\nDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\nInstalling collected packages: python-dotenv\nSuccessfully installed python-dotenv-1.1.0\n","output_type":"stream"}],"execution_count":1},{"id":"56cwlCFlDgAa","cell_type":"code","source":"from huggingface_hub import InferenceClient\nfrom dotenv import load_dotenv\nimport os","metadata":{"id":"56cwlCFlDgAa","executionInfo":{"status":"ok","timestamp":1746190665899,"user_tz":-180,"elapsed":4,"user":{"displayName":"–ù–∏–∫–∏—Ç–∞ –ë–ª–æ—Ö–∏–Ω","userId":"16402972581398673009"}},"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T22:31:19.976828Z","iopub.execute_input":"2025-05-29T22:31:19.977114Z","iopub.status.idle":"2025-05-29T22:31:20.590636Z","shell.execute_reply.started":"2025-05-29T22:31:19.977087Z","shell.execute_reply":"2025-05-29T22:31:20.590072Z"}},"outputs":[],"execution_count":2},{"id":"_aZ2UXeLEtFM","cell_type":"code","source":"load_dotenv(\"token.env\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_aZ2UXeLEtFM","executionInfo":{"status":"ok","timestamp":1746190659950,"user_tz":-180,"elapsed":4,"user":{"displayName":"–ù–∏–∫–∏—Ç–∞ –ë–ª–æ—Ö–∏–Ω","userId":"16402972581398673009"}},"outputId":"79bec2d8-1786-4270-8b5e-d69ecd510b2d","trusted":true,"execution":{"iopub.status.busy":"2025-05-29T22:31:21.894135Z","iopub.execute_input":"2025-05-29T22:31:21.894672Z","iopub.status.idle":"2025-05-29T22:31:21.899907Z","shell.execute_reply.started":"2025-05-29T22:31:21.894650Z","shell.execute_reply":"2025-05-29T22:31:21.899160Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}],"execution_count":3},{"id":"imEiY5VFDlNG","cell_type":"code","source":"model = \"gpt2\"\n\nclient = InferenceClient(\n    model=model,\n    token=os.getenv(\"HF_TOKEN_READ\")\n)","metadata":{"id":"imEiY5VFDlNG","executionInfo":{"status":"ok","timestamp":1746190700100,"user_tz":-180,"elapsed":5,"user":{"displayName":"–ù–∏–∫–∏—Ç–∞ –ë–ª–æ—Ö–∏–Ω","userId":"16402972581398673009"}},"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T22:31:30.195317Z","iopub.execute_input":"2025-05-29T22:31:30.196003Z","iopub.status.idle":"2025-05-29T22:31:30.199470Z","shell.execute_reply.started":"2025-05-29T22:31:30.195977Z","shell.execute_reply":"2025-05-29T22:31:30.198727Z"}},"outputs":[],"execution_count":8},{"id":"i8rialoSFa5P","cell_type":"code","source":"from google.colab import userdata","metadata":{"id":"i8rialoSFa5P","executionInfo":{"status":"ok","timestamp":1746190859639,"user_tz":-180,"elapsed":27,"user":{"displayName":"–ù–∏–∫–∏—Ç–∞ –ë–ª–æ—Ö–∏–Ω","userId":"16402972581398673009"}},"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T22:31:32.070614Z","iopub.execute_input":"2025-05-29T22:31:32.070892Z","iopub.status.idle":"2025-05-29T22:31:32.100051Z","shell.execute_reply.started":"2025-05-29T22:31:32.070872Z","shell.execute_reply":"2025-05-29T22:31:32.099326Z"}},"outputs":[],"execution_count":9},{"id":"QOAIi9EcE5Tb","cell_type":"code","source":"r = client.text_generation(\n    prompt=\"Student were upset because\"\n)\nr","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":368},"id":"QOAIi9EcE5Tb","executionInfo":{"status":"ok","timestamp":1746190784656,"user_tz":-180,"elapsed":23931,"user":{"displayName":"–ù–∏–∫–∏—Ç–∞ –ë–ª–æ—Ö–∏–Ω","userId":"16402972581398673009"}},"outputId":"57d8410c-8e4d-4f54-eb70-f2e126caa5a9","trusted":true,"execution":{"iopub.status.busy":"2025-05-29T22:31:33.830663Z","iopub.execute_input":"2025-05-29T22:31:33.831308Z","iopub.status.idle":"2025-05-29T22:31:34.382550Z","shell.execute_reply.started":"2025-05-29T22:31:33.831285Z","shell.execute_reply":"2025-05-29T22:31:34.381566Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/3784259487.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m r = client.text_generation(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Student were upset because\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/inference/_client.py\u001b[0m in \u001b[0;36mtext_generation\u001b[0;34m(self, prompt, details, stream, model, adapter_id, best_of, decoder_input_details, do_sample, frequency_penalty, grammar, max_new_tokens, repetition_penalty, return_full_text, seed, stop, stop_sequences, temperature, top_k, top_n_tokens, top_p, truncate, typical_p, watermark)\u001b[0m\n\u001b[1;32m   2295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2296\u001b[0m         \u001b[0mmodel_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2297\u001b[0;31m         \u001b[0mprovider_helper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_provider_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprovider\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-generation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2298\u001b[0m         request_parameters = provider_helper.prepare_request(\n\u001b[1;32m   2299\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/inference/_providers/__init__.py\u001b[0m in \u001b[0;36mget_provider_helper\u001b[0;34m(provider, task, model)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Specifying a model is required when provider is 'auto'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mprovider_mapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fetch_inference_provider_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mprovider\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprovider_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mprovider_tasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPROVIDERS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprovider\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mStopIteration\u001b[0m: "],"ename":"StopIteration","evalue":"","output_type":"error"}],"execution_count":10},{"id":"4GfKEcp9FiTX","cell_type":"code","source":"model = \"gpt2\"\n\nclient = InferenceClient(\n    model=model,\n    token=userdata.get('HF_TOKEN_SECRTER')\n)","metadata":{"id":"4GfKEcp9FiTX","trusted":true,"execution":{"iopub.status.busy":"2025-05-29T22:31:44.235740Z","iopub.execute_input":"2025-05-29T22:31:44.236257Z","iopub.status.idle":"2025-05-29T22:31:54.261401Z","shell.execute_reply.started":"2025-05-29T22:31:44.236232Z","shell.execute_reply":"2025-05-29T22:31:54.260548Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/702287467.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m client = InferenceClient(\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HF_TOKEN_SECRTER'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     64\u001b[0m     )\n\u001b[1;32m     65\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exists'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mSecretNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTimeoutException\u001b[0m: Requesting secret HF_TOKEN_SECRTER timed out. Secrets can only be fetched when running from the Colab UI."],"ename":"TimeoutException","evalue":"Requesting secret HF_TOKEN_SECRTER timed out. Secrets can only be fetched when running from the Colab UI.","output_type":"error"}],"execution_count":11},{"id":"lsOpHebBFgxP","cell_type":"code","source":"r = client.text_generation(\n    prompt=\"Student were upset because\"\n)\nr","metadata":{"id":"lsOpHebBFgxP","trusted":true,"execution":{"iopub.status.busy":"2025-05-29T22:31:57.673740Z","iopub.execute_input":"2025-05-29T22:31:57.674412Z","iopub.status.idle":"2025-05-29T22:31:57.683922Z","shell.execute_reply.started":"2025-05-29T22:31:57.674369Z","shell.execute_reply":"2025-05-29T22:31:57.683055Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/3784259487.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m r = client.text_generation(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Student were upset because\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/inference/_client.py\u001b[0m in \u001b[0;36mtext_generation\u001b[0;34m(self, prompt, details, stream, model, adapter_id, best_of, decoder_input_details, do_sample, frequency_penalty, grammar, max_new_tokens, repetition_penalty, return_full_text, seed, stop, stop_sequences, temperature, top_k, top_n_tokens, top_p, truncate, typical_p, watermark)\u001b[0m\n\u001b[1;32m   2295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2296\u001b[0m         \u001b[0mmodel_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2297\u001b[0;31m         \u001b[0mprovider_helper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_provider_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprovider\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-generation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2298\u001b[0m         request_parameters = provider_helper.prepare_request(\n\u001b[1;32m   2299\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/inference/_providers/__init__.py\u001b[0m in \u001b[0;36mget_provider_helper\u001b[0;34m(provider, task, model)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Specifying a model is required when provider is 'auto'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mprovider_mapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fetch_inference_provider_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mprovider\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprovider_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mprovider_tasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPROVIDERS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprovider\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mStopIteration\u001b[0m: "],"ename":"StopIteration","evalue":"","output_type":"error"}],"execution_count":12},{"id":"77d624a0","cell_type":"markdown","source":"## –ó–∞–¥–∞—á–∏ –¥–ª—è —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è","metadata":{"id":"77d624a0"}},{"id":"b90b59bb","cell_type":"markdown","source":"<p class=\"task\" id=\"1\"></p>\n\n1\\. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –ª—é–±—É—é –±–æ–ª—å—à—É—é —è–∑—ã–∫–æ–≤—É—é –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ –∏–∑ ü§ó Transformers. –ò—Å–ø–æ–ª—å–∑—É—è –¥–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å, –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ —Ç–µ–∫—Å—Ç `prompt`. –ò–∑—É—á–∏—Ç–µ, –∫–∞–∫ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤–ª–∏—è—é—Ç —Å–ª–µ–¥—É—é—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\n\n* max_new_tokens;\n* do_sample;\n* num_beams;\n* num_beam_groups.\n\n–í—ã–≤–µ–¥–∏—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —Å —Ä–∞–∑–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏.\n\n\n- [ ] –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ –Ω–∞ —Å–µ–º–∏–Ω–∞—Ä–µ","metadata":{"id":"b90b59bb"}},{"id":"3c427408-4755-4cbb-ae65-d3c42b73bf11","cell_type":"code","source":"!pip -q install --upgrade --no-cache-dir transformers accelerate sentencepiece bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:20:02.423285Z","iopub.execute_input":"2025-05-30T15:20:02.423946Z","iopub.status.idle":"2025-05-30T15:21:15.497765Z","shell.execute_reply.started":"2025-05-30T15:20:02.423918Z","shell.execute_reply":"2025-05-30T15:21:15.496854Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m215.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m362.1/362.1 kB\u001b[0m \u001b[31m345.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m274.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m273.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m269.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m272.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m289.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m325.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m288.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m289.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"id":"f9db06d1-1f06-4789-8a28-4218805d19fe","cell_type":"code","source":"from pathlib import Path\n\nCACHE_DIR = Path(\"/kaggle/working/hf_cache\")\nCACHE_DIR.mkdir(exist_ok=True, parents=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:21:15.499329Z","iopub.execute_input":"2025-05-30T15:21:15.499915Z","iopub.status.idle":"2025-05-30T15:21:15.503864Z","shell.execute_reply.started":"2025-05-30T15:21:15.499889Z","shell.execute_reply":"2025-05-30T15:21:15.503275Z"}},"outputs":[],"execution_count":2},{"id":"2b7908ac-22f5-4d93-9df3-35dc7a44e988","cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer\n\nMODEL_ID = \"ai-forever/rugpt3medium_based_on_gpt2\"   # ‚âà760 –ú –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\nDTYPE    = torch.float16                              # —ç–∫–æ–Ω–æ–º–∏–º –ø–∞–º—è—Ç—å\n\ntok = AutoTokenizer.from_pretrained(MODEL_ID, cache_dir=CACHE_DIR)\nmodel = AutoModelForCausalLM.from_pretrained(\n            MODEL_ID,\n            torch_dtype=DTYPE,\n            device_map=\"auto\",        # ¬´—Ä–∞—Å–∫–∏–Ω–µ—Ç¬ª —Å–ª–æ–∏ –ø–æ –¥–æ—Å—Ç—É–ø–Ω—ã–º GPU\n            cache_dir=CACHE_DIR\n        ).eval()\n\nstreamer = TextStreamer(tok, skip_special_tokens=True)\nprint(\"–º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω—ã\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:21:15.504528Z","iopub.execute_input":"2025-05-30T15:21:15.504705Z","iopub.status.idle":"2025-05-30T15:21:55.869628Z","shell.execute_reply.started":"2025-05-30T15:21:15.504687Z","shell.execute_reply":"2025-05-30T15:21:55.868649Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.25k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa75cd1b5ae5413d8273c0967af8f0a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.61M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9f9e07a01a043b386c9254c6e243134"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.27M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef2b6cc4f5ab46708264146cbba1421d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/574 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db474a7064ec4830a5e51cf0473c4fc6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/761 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b47c7378934749f79ca43ca13e3ca101"}},"metadata":{}},{"name":"stderr","text":"2025-05-30 15:21:33.162692: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748618493.391420      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748618493.458807      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.73G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c732cef49e84692a00eebde7da71de4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.73G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e72798fd958e4b829719fd904187d1fd"}},"metadata":{}},{"name":"stdout","text":"–º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω—ã\n","output_type":"stream"}],"execution_count":3},{"id":"ee2d511b-7af8-4f63-8c78-cc2c999ea332","cell_type":"code","source":"import textwrap\n\ndef generate_ru(prompt:str,\n                max_new_tokens:int = 60,\n                do_sample:bool = False,\n                num_beams:int | None = None,\n                num_beam_groups:int | None = None,\n                streamer=None,\n                **sampling):\n\n    inputs = tok(prompt, return_tensors=\"pt\").to(model.device)\n\n    gen_kwargs = dict(\n        max_new_tokens = max_new_tokens,\n        do_sample      = do_sample,\n        streamer       = streamer,\n        **sampling\n    )\n    if num_beams is not None:       # ‚Üê –¥–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∑–∞–¥–∞–Ω–æ\n        gen_kwargs[\"num_beams\"] = num_beams\n    if num_beam_groups is not None: # ‚Üê –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ\n        gen_kwargs[\"num_beam_groups\"] = num_beam_groups\n\n    with torch.inference_mode():\n        out_ids = model.generate(**inputs, **gen_kwargs)\n\n    return tok.decode(out_ids[0], skip_special_tokens=True)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:21:55.872503Z","iopub.execute_input":"2025-05-30T15:21:55.873104Z","iopub.status.idle":"2025-05-30T15:21:55.879286Z","shell.execute_reply.started":"2025-05-30T15:21:55.873082Z","shell.execute_reply":"2025-05-30T15:21:55.878543Z"}},"outputs":[],"execution_count":4},{"id":"21373933-ac3c-45e2-a57b-a0cdc719f8e4","cell_type":"code","source":"PROMPT = \"–ê–Ω–µ–∫–¥–æ—Ç, —Å–∏–¥—è—Ç –≤ –±–∞—Ä–µ —Ä—É—Å—Å–∫–∏–π, –∞–º–µ—Ä–∏–∫–∞–Ω–µ—Ü –∏ –∫–∏—Ç–∞–µ—Ü\"\n\nprint(\"‚Äî GREEDY (baseline) ‚Äî\")\nprint(textwrap.fill(\n      generate_ru(PROMPT, max_new_tokens=60, do_sample=False),\n      width=100), \"\\n\")\n\nprint(\"‚Äî SAMPLING (top-p 0.9, T=0.7) ‚Äî\")\nprint(textwrap.fill(\n      generate_ru(PROMPT, max_new_tokens=60, do_sample=True,\n                  top_p=0.9, temperature=0.7),\n      width=100), \"\\n\")\n\nprint(\"‚Äî BEAM SEARCH (num_beams = 5) ‚Äî\")\nprint(textwrap.fill(\n      generate_ru(PROMPT, max_new_tokens=60, num_beams=5),\n      width=100), \"\\n\")\n\nprint(\"‚Äî DIVERSE BEAM (6 beams, 3 groups) ‚Äî\")\nprint(textwrap.fill(\n      generate_ru(PROMPT, max_new_tokens=60, num_beams=6, num_beam_groups=3, diversity_penalty = 0.7),\n      width=100), \"\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:21:55.881060Z","iopub.execute_input":"2025-05-30T15:21:55.881438Z","iopub.status.idle":"2025-05-30T15:22:03.286262Z","shell.execute_reply.started":"2025-05-30T15:21:55.881421Z","shell.execute_reply":"2025-05-30T15:22:03.285592Z"}},"outputs":[{"name":"stdout","text":"‚Äî GREEDY (baseline) ‚Äî\n–ê–Ω–µ–∫–¥–æ—Ç, —Å–∏–¥—è—Ç –≤ –±–∞—Ä–µ —Ä—É—Å—Å–∫–∏–π, –∞–º–µ—Ä–∏–∫–∞–Ω–µ—Ü –∏ –∫–∏—Ç–∞–µ—Ü.  –†—É—Å—Å–∫–∏–π –≥–æ–≤–æ—Ä–∏—Ç: - –Ø –Ω–µ –ø–æ–Ω–∏–º–∞—é, –ø–æ—á–µ–º—É –≤\n–†–æ—Å—Å–∏–∏ —Ç–∞–∫ –º–Ω–æ–≥–æ –∫–∏—Ç–∞–π—Ü–µ–≤?  –ê–º–µ—Ä–∏–∫–∞–Ω–µ—Ü: - –ê —Ç—ã –ø–æ—Å–º–æ—Ç—Ä–∏ –Ω–∞ —Ä—É—Å—Å–∫–∏—Ö.  –û–Ω–∏ –≤—Å–µ —Ç–∞–∫–∏–µ –∂–µ.  –†—É—Å—Å–∫–∏–π: -\n–î–∞, –Ω–æ –ø–æ—á–µ–º—É –æ–Ω–∏ —Ç–∞–∫–∏–µ –∂–µ?  –ê–º–µ—Ä–∏–∫–∞–Ω–µ—Ü: - –ê —Ç—ã –ø–æ—Å–º–æ—Ç—Ä–∏ –Ω–∞ —Ä—É—Å—Å–∫–∏—Ö.  –û–Ω–∏ –≤—Å–µ \n\n‚Äî SAMPLING (top-p 0.9, T=0.7) ‚Äî\n–ê–Ω–µ–∫–¥–æ—Ç, —Å–∏–¥—è—Ç –≤ –±–∞—Ä–µ —Ä—É—Å—Å–∫–∏–π, –∞–º–µ—Ä–∏–∫–∞–Ω–µ—Ü –∏ –∫–∏—Ç–∞–µ—Ü, –ø—å—é—Ç –ø–∏–≤–æ, —Ä—É—Å—Å–∫–∏–π –≥–æ–≤–æ—Ä–∏—Ç: - –ß—Ç–æ –≤—ã –º–Ω–µ\n–ø–æ—Å–æ–≤–µ—Ç—É–µ—Ç–µ? - –ù—É, –∫–∞–∫ —á—Ç–æ, –¥–∞–≤–∞–π—Ç–µ –≤—ã–ø—å–µ–º –∑–∞ —Ç–æ, —á—Ç–æ –º—ã —Ä—É—Å—Å–∫–∏–µ! - –ê —è - –∑–∞ —Ç–æ, —á—Ç–æ –º—ã –∞–º–µ—Ä–∏–∫–∞–Ω—Ü—ã!\n- –ê —è - –∑–∞ —Ç–æ, —á—Ç–æ –º—ã –∫–∏—Ç–∞–π—Ü—ã! - –ê —è - –∑–∞ —Ç–æ, \n\n‚Äî BEAM SEARCH (num_beams = 5) ‚Äî\n–ê–Ω–µ–∫–¥–æ—Ç, —Å–∏–¥—è—Ç –≤ –±–∞—Ä–µ —Ä—É—Å—Å–∫–∏–π, –∞–º–µ—Ä–∏–∫–∞–Ω–µ—Ü –∏ –∫–∏—Ç–∞–µ—Ü.  –ê–º–µ—Ä–∏–∫–∞–Ω–µ—Ü —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç —Ä—É—Å—Å–∫–æ–≥–æ: - –°–ª—É—à–∞–π, –∞\n–ø–æ—á–µ–º—É —Ç—ã –Ω–µ –ø—å–µ—à—å?  –ê —Ç–æ—Ç –µ–º—É –≤ –æ—Ç–≤–µ—Ç: - –ü–æ—Ç–æ–º—É —á—Ç–æ —É –º–µ–Ω—è –Ω–µ—Ç –¥–µ–Ω–µ–≥.  –ê–º–µ—Ä–∏–∫–∞–Ω–µ—Ü: - –ê –ø–æ—á–µ–º—É —Ç—ã –Ω–µ\n–ø—å–µ—à—å?  –ê —Ç–æ—Ç –µ–º—É –≤ –æ—Ç–≤–µ—Ç: - –ü–æ—Ç–æ–º—É —á—Ç–æ —É –º–µ–Ω—è –Ω–µ—Ç –¥–µ–Ω–µ–≥. \n\n‚Äî DIVERSE BEAM (6 beams, 3 groups) ‚Äî\n–ê–Ω–µ–∫–¥–æ—Ç, —Å–∏–¥—è—Ç –≤ –±–∞—Ä–µ —Ä—É—Å—Å–∫–∏–π, –∞–º–µ—Ä–∏–∫–∞–Ω–µ—Ü –∏ –∫–∏—Ç–∞–µ—Ü.  –ê–º–µ—Ä–∏–∫–∞–Ω–µ—Ü –≥–æ–≤–æ—Ä–∏—Ç: - –Ø –Ω–µ –ø–æ–Ω–∏–º–∞—é, –ø–æ—á–µ–º—É\n—Ä—É—Å—Å–∫–∏–µ –ø—å—é—Ç –≤–æ–¥–∫—É, –∞ –∫–∏—Ç–∞–π—Ü—ã - –ø–∏–≤–æ?  –†—É—Å—Å–∫–∏–π –æ—Ç–≤–µ—á–∞–µ—Ç: - –ü–æ—Ç–æ–º—É —á—Ç–æ —Ä—É—Å—Å–∫–∏–µ –ø—å—é—Ç –≤–æ–¥–∫—É, –∞ –∫–∏—Ç–∞–π—Ü—ã\n- –ø–∏–≤–æ.  –ê–Ω–µ–∫–¥–æ—Ç, —Å–∏–¥—è—Ç –≤ –±–∞—Ä–µ —Ä—É—Å—Å–∫–∏–π, –∞–º–µ—Ä–∏–∫–∞–Ω–µ—Ü –∏ –∫–∏—Ç–∞–µ—Ü.  –ê–º–µ—Ä–∏–∫–∞–Ω–µ—Ü –≥–æ–≤–æ—Ä–∏—Ç: - –Ø \n\n","output_type":"stream"}],"execution_count":5},{"id":"fa8938b0-9c7c-4c3d-a843-cbf981deaa04","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"13659564","cell_type":"markdown","source":"<p class=\"task\" id=\"2\"></p>\n\n2\\. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –ª—é–±—É—é –±–æ–ª—å—à—É—é —è–∑—ã–∫–æ–≤—É—é –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ –∏–∑ ü§ó Transformers. –ü—Ä–∏–¥—É–º–∞–π—Ç–µ prompt, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª–∏—Ç –ø–æ —Ç–µ–∫—Å—Ç—É –≤–æ–ø—Ä–æ—Å–∞ –∏–∑ —Ñ–∞–π–ª–æ–≤ –∫–∞—Ç–∞–ª–æ–≥–∞ `qst_eng_txt/questions` –≤—ã–¥–µ–ª–∏—Ç—å –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—É—é —Å—É—â–Ω–æ—Å—Ç—å –∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∏–Ω—Ç–µ–Ω—Ç –≤–æ–ø—Ä–æ—Å–∞. –ü—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–π—Ç–µ —Ä–∞–±–æ—Ç—É –º–æ–¥–µ–ª–∏ –Ω–∞ –ø—Ä–∏–º–µ—Ä–∞—Ö —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏–Ω—Ç–µ–Ω—Ç–æ–≤.\n\n–í —Å–ª—É—á–∞–µ –Ω–µ—Ö–≤–∞—Ç–∫–∏ —Ä–µ—Å—É—Ä—Å–æ–≤ –Ω–∞ –º–∞—à–∏–Ω–µ –¥–ª—è —Ä–∞–∑–≤–æ—Ä–∞—á–∏–≤–∞–Ω–∏—è —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –≤—ã –º–æ–∂–µ—Ç–µ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è Inference API ü§ó Transformers.\n\n–°–æ–≤–µ—Ç—ã –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é –ø—Ä–æ–º–ø—Ç–∞:\n* –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —á–µ—Ç–∫–æ –æ–ø–∏—à–∏—Ç–µ, —á—Ç–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ –ø–æ–ª—É—á–∏—Ç—å –Ω–∞ –≤—ã—Ö–æ–¥–µ;\n* –º–æ–∂–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å –≤ –ø—Ä–æ–º–ø—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –≤–æ–ø—Ä–æ—Å–æ–≤, –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –∏ —Ñ–æ—Ä–º–∞—Ç–∞ –æ—Ç–≤–µ—Ç–æ–≤.\n\n\n\n- [ ] –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ –Ω–∞ —Å–µ–º–∏–Ω–∞—Ä–µ","metadata":{"id":"13659564"}},{"id":"c724ea9d-1339-4135-95c5-cd3245f868e5","cell_type":"code","source":"import pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:22:03.286914Z","iopub.execute_input":"2025-05-30T15:22:03.287145Z","iopub.status.idle":"2025-05-30T15:22:03.290843Z","shell.execute_reply.started":"2025-05-30T15:22:03.287104Z","shell.execute_reply":"2025-05-30T15:22:03.290089Z"}},"outputs":[],"execution_count":6},{"id":"206abd60-5aba-43a9-a69a-7bd9f4d62e90","cell_type":"code","source":"df = pd.read_csv('/kaggle/input/lab-13-nlp/qst_eng_txt/questions/film_actors.csv')\ndf.head(7)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:22:03.291567Z","iopub.execute_input":"2025-05-30T15:22:03.291764Z","iopub.status.idle":"2025-05-30T15:22:05.466055Z","shell.execute_reply.started":"2025-05-30T15:22:03.291748Z","shell.execute_reply":"2025-05-30T15:22:05.465475Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                         question\n0      Can you name the Main Actors of inception?\n1    who portrayed the lead roles in \"inception\"?\n2                       Pulp Fiction main actors?\n3  Who were the main actors in \"The Dark Knight\"?\n4       Who were the main actors in \"The Matrix\"?\n5        Who played the main actors in Inception?\n6                          inception main actors?","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Can you name the Main Actors of inception?</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>who portrayed the lead roles in \"inception\"?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Pulp Fiction main actors?</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Who were the main actors in \"The Dark Knight\"?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Who were the main actors in \"The Matrix\"?</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Who played the main actors in Inception?</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>inception main actors?</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"id":"f132ce10-89ff-4098-91c3-391e1c1dd669","cell_type":"code","source":"path = '/kaggle/input/lab-13-nlp/qst_eng_txt/questions/'\nq = 'question'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:22:05.466821Z","iopub.execute_input":"2025-05-30T15:22:05.467079Z","iopub.status.idle":"2025-05-30T15:22:07.094033Z","shell.execute_reply.started":"2025-05-30T15:22:05.467052Z","shell.execute_reply":"2025-05-30T15:22:07.093006Z"}},"outputs":[],"execution_count":8},{"id":"179d45b5-ac35-4260-8902-3f7348efaf5a","cell_type":"code","source":"q1 = pd.read_csv(path+'film_actors.csv')[q].to_list() #actors\nq2 = pd.read_csv(path+'film_cameraman.csv')[q].to_list() #cameraman\nq3 = pd.read_csv(path+'film_director.csv')[q].to_list() #director","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:22:07.094763Z","iopub.execute_input":"2025-05-30T15:22:07.095042Z","iopub.status.idle":"2025-05-30T15:22:08.514352Z","shell.execute_reply.started":"2025-05-30T15:22:07.095017Z","shell.execute_reply":"2025-05-30T15:22:08.513784Z"}},"outputs":[],"execution_count":9},{"id":"e702afc6-035e-4b01-8f65-87ab8eab2ee8","cell_type":"code","source":"questions = q1 + q2 + q3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:22:08.516299Z","iopub.execute_input":"2025-05-30T15:22:08.516568Z","iopub.status.idle":"2025-05-30T15:22:09.896213Z","shell.execute_reply.started":"2025-05-30T15:22:08.516551Z","shell.execute_reply":"2025-05-30T15:22:09.895375Z"}},"outputs":[],"execution_count":10},{"id":"69660c23-4f9f-406f-a31f-88e7fe25ba5d","cell_type":"code","source":"from random import shuffle","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:22:09.897190Z","iopub.execute_input":"2025-05-30T15:22:09.897472Z","iopub.status.idle":"2025-05-30T15:22:11.171443Z","shell.execute_reply.started":"2025-05-30T15:22:09.897447Z","shell.execute_reply":"2025-05-30T15:22:11.170466Z"}},"outputs":[],"execution_count":11},{"id":"3ae890b5-e23b-4de0-8939-73727ff813e2","cell_type":"code","source":"shuffle(questions)\nquestions[:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:22:11.172410Z","iopub.execute_input":"2025-05-30T15:22:11.172674Z","iopub.status.idle":"2025-05-30T15:22:12.608887Z","shell.execute_reply.started":"2025-05-30T15:22:11.172647Z","shell.execute_reply":"2025-05-30T15:22:12.608011Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"['List directors The Dark Knight.',\n 'Can you tell me the main actors of \"Pulp Fiction\"?',\n 'Can you name the Main Actors of The Dark Knight?',\n 'who portrayed the lead roles in \"inception\"?',\n 'Can you name the Cameraman of Blade Runner 2049?']"},"metadata":{}}],"execution_count":12},{"id":"b06569cd-e085-4a78-8bbc-334a310a7c64","cell_type":"code","source":"import torch, json\nfrom transformers import pipeline\n\nMODEL_NAME = \"google/flan-t5-base\"\n\ngenerator = pipeline(\n    \"text2text-generation\",\n    model=MODEL_NAME,\n    tokenizer=MODEL_NAME,\n    device=0 if torch.cuda.is_available() else -1,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:22:12.609732Z","iopub.execute_input":"2025-05-30T15:22:12.610259Z","iopub.status.idle":"2025-05-30T15:22:22.847086Z","shell.execute_reply.started":"2025-05-30T15:22:12.610230Z","shell.execute_reply":"2025-05-30T15:22:22.846532Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f87e7c776011430db17b35b4633203f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bc9328359094111a93cf7e8af5e660e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cb48a7d26a1422bae113a943ca1bc83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b180920c0d974e4b8f3dd838e1fe45ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b55354e6c334d56a42cb34dc9ee7408"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d3d10de2b4141028eb830c78811bf4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ede672cab974cc9a5d35b29f31e6b9b"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":13},{"id":"bbd8a0d4-7a98-4209-81ea-2f7e85400cc2","cell_type":"code","source":"PROMPT_TEMPLATE = \"\"\"Extract the film title and intent from the following English question.\n\nOutput will be like that:\n    \"entity\":\"La La Land\",\"intent\":\"film_cameraman\"\n\n‚Äì **entity**: the title of a film (proper name, exactly as it appears in the question)  \n‚Äì **intent**: one of the following three values:\n  ‚Ä¢ film_director  \n  ‚Ä¢ film_cameraman  \n  ‚Ä¢ film_actors  \n\nExamples:\nQ: Can you name the Director of Inception?\nA: \"entity\":\"Inception\",\"intent\":\"film_director\"\n\nQ: Who operated the camera for La La Land?\nA: \"entity\":\"La La Land\",\"intent\":\"film_cameraman\"\n\nQ: Who were the main actors in \"The Matrix\"?\nA: \"entity\":\"The Matrix\",\"intent\":\"film_actors\"\n\nQ: {question}\nA:\"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:22:22.847894Z","iopub.execute_input":"2025-05-30T15:22:22.848189Z","iopub.status.idle":"2025-05-30T15:22:22.852490Z","shell.execute_reply.started":"2025-05-30T15:22:22.848164Z","shell.execute_reply":"2025-05-30T15:22:22.851678Z"}},"outputs":[],"execution_count":14},{"id":"d692a291-4f51-4b5e-a130-4e497f8c883b","cell_type":"code","source":"def extract_entity_intent(question: str) -> dict:\n    prompt = PROMPT_TEMPLATE.format(question=question)\n    out = generator(\n        prompt,\n        max_new_tokens=150,\n        do_sample=False,\n        num_beams=10\n    )[0][\"generated_text\"].strip()\n\n    # out –±—É–¥–µ—Ç —Å—Ç—Ä–æ–∫–æ–π –≤–∏–¥–∞ '{\"entity\":\"Inception\",\"intent\":\"film_director\"}'\n    # return out\n    # print(out)\n\n    # if 'entity' in out.lower() and 'intent' in out.lower():\n    #     return eval('{'+out+'}')\n\n    intents = ['film_director',\n               'film_cameraman',\n               'film_actors'\n              ]\n\n    res = dict()\n\n    splited_out = out.split(',')\n    \n    for i in splited_out:\n        if 'entity' in i:\n            res['entity'] = i.split(':')[-1].replace('\"', '')\n        if 'intent' in i:\n            res['intent'] = i.split(':')[-1].replace('\"', '')\n        if intents[0] in i:\n            res['intent'] = intents[0]\n        if intents[1] in i:\n            res['intent'] = intents[1]\n        if intents[2] in i:\n            res['intent'] = intents[2]\n        \n            \n    return res","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:42:09.498600Z","iopub.execute_input":"2025-05-30T15:42:09.499320Z","iopub.status.idle":"2025-05-30T15:42:09.504593Z","shell.execute_reply.started":"2025-05-30T15:42:09.499298Z","shell.execute_reply":"2025-05-30T15:42:09.503934Z"}},"outputs":[],"execution_count":60},{"id":"5bfe6b54-e74a-4789-9d9b-7cfe71f51b54","cell_type":"code","source":"extract_entity_intent(question)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T17:02:34.285462Z","iopub.execute_input":"2025-05-30T17:02:34.286115Z","iopub.status.idle":"2025-05-30T17:02:34.837849Z","shell.execute_reply.started":"2025-05-30T17:02:34.286094Z","shell.execute_reply":"2025-05-30T17:02:34.837176Z"}},"outputs":[{"execution_count":130,"output_type":"execute_result","data":{"text/plain":"{'entity': 'La La Land', 'intent': 'film_cameraman'}"},"metadata":{}}],"execution_count":130},{"id":"2c99c070-e490-4d18-bc6c-9decc05536a7","cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:32:12.337689Z","iopub.execute_input":"2025-05-30T15:32:12.338310Z","iopub.status.idle":"2025-05-30T15:32:12.342806Z","shell.execute_reply.started":"2025-05-30T15:32:12.338289Z","shell.execute_reply":"2025-05-30T15:32:12.341985Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"{'1': '1'}"},"metadata":{}}],"execution_count":36},{"id":"45ae51ce-bac2-46c2-8a8e-bc59352e9f4b","cell_type":"code","source":"shuffle(questions)\n\n\nfor question in questions[:5]:\n    result_text = extract_entity_intent(question)\n    print('--------------------')\n    print('question:', question)\n    print()\n    print(result_text, type(result_text))\n    print('--------------------')\n    print()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:42:15.009816Z","iopub.execute_input":"2025-05-30T15:42:15.010332Z","iopub.status.idle":"2025-05-30T15:42:17.591765Z","shell.execute_reply.started":"2025-05-30T15:42:15.010304Z","shell.execute_reply":"2025-05-30T15:42:17.591152Z"}},"outputs":[{"name":"stdout","text":"--------------------\nquestion: forrest gump director?\n\n{'entity': 'Forrest Gump', 'intent': 'film_director'} <class 'dict'>\n--------------------\n\n--------------------\nquestion: Who directed The Shawshank Redemption?\n\n{'entity': 'The Shawshank Redemption', 'intent': 'film_director'} <class 'dict'>\n--------------------\n\n--------------------\nquestion: Can you name the Cameraman of Blade Runner 2049?\n\n{'entity': 'Blade Runner 2049', 'intent': 'film_cameraman'} <class 'dict'>\n--------------------\n\n--------------------\nquestion: list actors Forrest Gump.\n\n{'entity': 'Forrest Gump', 'intent': 'film_actors'} <class 'dict'>\n--------------------\n\n--------------------\nquestion: Can you name the Main Actors of The Dark Knight?\n\n{'entity': 'The Dark Knight', 'intent': 'film_actors'} <class 'dict'>\n--------------------\n\n","output_type":"stream"}],"execution_count":62},{"id":"87ce97f2","cell_type":"markdown","source":"<p class=\"task\" id=\"3\"></p>\n\n3\\. –°–æ–∑–¥–∞–π—Ç–µ —Å–ª–æ–≤–∞—Ä—å `db` —Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–∏–¥–∞:\n```\n{\n    \"film_director\": {\n        \"The Shawshank Redemption\": \"Frank Darabont\",\n        ...\n    },\n    ...\n}\n```\n\n–ù–∞–ø–∏—à–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏–∏ `parse_llm_result` –∏ `find_answer`. –ü—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–π—Ç–µ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö.\n\n\n- [ ] –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ –Ω–∞ —Å–µ–º–∏–Ω–∞—Ä–µ","metadata":{"id":"87ce97f2"}},{"id":"8c829c51-4416-44d2-9bab-20c4551e96fe","cell_type":"code","source":"path_answer = '/kaggle/input/lab-13-nlp/qst_eng_txt/answers/'\n\na1 = pd.read_csv(path_answer + 'film_actors.csv')\na2 = pd.read_csv(path_answer + 'film_cameraman.csv')\na3 = pd.read_csv(path_answer + 'film_director.csv')\n\ndata = {\n    'film_actors': a1,\n    'film_cameraman': a2,\n    'film_director': a3\n}\n\ndb = {}\n\nfor k, v in data.items():\n    base = {}\n\n    for idx, val in v.iterrows():\n        entity, answer = val\n        base[entity] = answer\n\n    db[k] = base","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:42:27.009275Z","iopub.execute_input":"2025-05-30T15:42:27.009554Z","iopub.status.idle":"2025-05-30T15:42:27.035412Z","shell.execute_reply.started":"2025-05-30T15:42:27.009536Z","shell.execute_reply":"2025-05-30T15:42:27.034895Z"}},"outputs":[],"execution_count":63},{"id":"d8aab9a9-9ef1-488e-b680-8fce75b88a88","cell_type":"code","source":"db.keys(), db['film_actors']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:42:27.109463Z","iopub.execute_input":"2025-05-30T15:42:27.109672Z","iopub.status.idle":"2025-05-30T15:42:27.114198Z","shell.execute_reply.started":"2025-05-30T15:42:27.109657Z","shell.execute_reply":"2025-05-30T15:42:27.113662Z"}},"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"(dict_keys(['film_actors', 'film_cameraman', 'film_director']),\n {'The Matrix': 'Keanu Reeves, Laurence Fishburne, Carrie-Anne Moss, and others.',\n  'The Dark Knight': 'Christian Bale and Heath Ledger.',\n  'Pulp Fiction': 'John Travolta, Uma Thurman, and Samuel L. Jackson.',\n  'Inception': 'Leonardo DiCaprio, Joseph Gordon-Levitt, Ellen Page, and others.',\n  'Forrest Gump': 'Tom Hanks, Robin Wright, Gary Sinise, and others.'})"},"metadata":{}}],"execution_count":64},{"id":"45671a3c-80fa-4f87-8ba0-a210d4cdf1cb","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"5a464ece-f21b-4973-a454-d8f91b16c4b5","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"dd1009f2","cell_type":"code","source":"# c–¥–µ–ª–∞–ª –µ—â–µ –≤ –ø—Ä–æ—à–ª–æ–º –ø—É–Ω–∫—Ç–µ extract_entity_intent(question)\n\n\n# def parse_llm_result(result: str) -> tuple[str, str]:\n#     \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ç–µ–Ω—Ç –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏ –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM\"\"\"\n#     pass","metadata":{"id":"dd1009f2"},"outputs":[],"execution_count":null},{"id":"4384b616-14f0-4473-bfe5-1213754ed786","cell_type":"code","source":"pip install thefuzz","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:45:40.506585Z","iopub.execute_input":"2025-05-30T15:45:40.507165Z","iopub.status.idle":"2025-05-30T15:45:45.118589Z","shell.execute_reply.started":"2025-05-30T15:45:40.507145Z","shell.execute_reply":"2025-05-30T15:45:45.117613Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting thefuzz\n  Downloading thefuzz-0.22.1-py3-none-any.whl.metadata (3.9 kB)\nCollecting rapidfuzz<4.0.0,>=3.0.0 (from thefuzz)\n  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nDownloading thefuzz-0.22.1-py3-none-any.whl (8.2 kB)\nDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rapidfuzz, thefuzz\nSuccessfully installed rapidfuzz-3.13.0 thefuzz-0.22.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":72},{"id":"75178627-a0e3-4268-8316-732c5e4af27b","cell_type":"code","source":"from thefuzz import process","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:45:49.407963Z","iopub.execute_input":"2025-05-30T15:45:49.408460Z","iopub.status.idle":"2025-05-30T15:45:49.411691Z","shell.execute_reply.started":"2025-05-30T15:45:49.408437Z","shell.execute_reply":"2025-05-30T15:45:49.411026Z"}},"outputs":[],"execution_count":74},{"id":"1e9b92a3","cell_type":"code","source":"def find_answer(entity: str, intent: str, db: dict) -> tuple[str, int]:\n    \"\"\"entity - —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã get_entity,intent - —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã get_intent\n    –î–ª—è –ø–æ–∏—Å–∫–∞ –∫–ª—é—á–∞ –≤ —Å–ª–æ–≤–∞—Ä–µ db[intent] –≤–æ—Å–ø–æ–ª—å–∑—É–π—Ç–µ—Å—å –º–µ—Ç–æ–¥–æ–º process.extractOne –∏–∑ –ø–∞–∫–µ—Ç–∞ thefuzz\n    \"\"\"\n    options = db.get(intent, {})\n\n    if not options:\n        return (\"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –≤–æ–ø—Ä–æ—Å–∞\", 0)\n\n    best_match, score = process.extractOne(entity, options.keys())\n    return (options[best_match], score)","metadata":{"id":"1e9b92a3","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:45:51.911580Z","iopub.execute_input":"2025-05-30T15:45:51.912058Z","iopub.status.idle":"2025-05-30T15:45:51.916477Z","shell.execute_reply.started":"2025-05-30T15:45:51.912038Z","shell.execute_reply":"2025-05-30T15:45:51.915772Z"}},"outputs":[],"execution_count":75},{"id":"7bf57cce-b5f3-432b-8e7c-c69b31fb8305","cell_type":"code","source":"shuffle(questions)\n\n\nfor question in questions[:5]:\n    X = extract_entity_intent(question)\n    result = find_answer(X.get('entity', ''), X.get('intent', ''), db)\n    print('--------------------')\n    print('question:', question)\n    print()\n    print(result)\n    print('--------------------')\n    print()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T15:45:52.076669Z","iopub.execute_input":"2025-05-30T15:45:52.076905Z","iopub.status.idle":"2025-05-30T15:45:54.502198Z","shell.execute_reply.started":"2025-05-30T15:45:52.076887Z","shell.execute_reply":"2025-05-30T15:45:54.501386Z"}},"outputs":[{"name":"stdout","text":"--------------------\nquestion: la la land cameraman?\n\n('Linus Sandgren.', 100)\n--------------------\n\n--------------------\nquestion: Can you name the Cameraman of Mad Max\n\n('John Seale.', 100)\n--------------------\n\n--------------------\nquestion: List directors Inception.\n\n('Christopher Nolan.', 100)\n--------------------\n\n--------------------\nquestion: List cameramen Mad Max\n\n('John Seale.', 100)\n--------------------\n\n--------------------\nquestion: blade runner 2049 cameraman?\n\n('Linus Sandgren.', 100)\n--------------------\n\n","output_type":"stream"}],"execution_count":76},{"id":"1ede29a4","cell_type":"markdown","source":"<p class=\"task\" id=\"4\"></p>\n\n4\\. –†–µ–∞–ª–∏–∑—É–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –≤–µ–¥–µ–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞ —Å LLM –ø–æ —Å–ª–µ–¥—É—é—â–µ–º—É –ø—Ä–∏–Ω—Ü–∏–ø—É.\n\n–í–∞–º –¥–∞–Ω –Ω–∞—á–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ `context`.\n\n```\nSome context\n```\n\n–í—ã –ø—Ä–∏–¥—É–º—ã–≤–∞–µ—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏ —Ä–∞—Å—à–∏—Ä—è–µ—Ç–µ —Å—Ç—Ä–æ–∫—É —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º:\n```\nSome context\n\nUser: some message\n```\n\n–î–∞–ª–µ–µ –≤—ã –ø–µ—Ä–µ–¥–∞–µ—Ç–µ –ø–æ–ª—É—á–µ–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É –≤ LLM –∏ —Ä–∞—Å—à–∏—Ä—è–µ—Ç–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç–≤–µ—Ç–∞, —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –º–æ–¥–µ–ª—å—é:\n\n```\nSome context\n\nUser: some message\n\nAI: some answer\n```\n\n–û–±–º–µ–Ω—è–π—Ç–µ—Å—å —Å —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª—å—é –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —Ä–µ–ø–ª–∏–∫–∞–º–∏ –≤ —Ç–∞–∫–æ–º —Å—Ç–∏–ª–µ –∏ –ø–æ–∫–∞–∂–∏—Ç–µ, —á—Ç–æ —É —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –ø–æ–ª—É—á–∞–µ—Ç—Å—è –∏–∑–≤–ª–µ–∫–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.\n- [ ] –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ –Ω–∞ —Å–µ–º–∏–Ω–∞—Ä–µ","metadata":{"id":"1ede29a4"}},{"id":"ecde96a1-fde5-496a-9f60-40c048a4a1a4","cell_type":"code","source":"import torch, json\nfrom transformers import pipeline\n\nMODEL_NAME = \"google/flan-t5-base\"\n\ngenerator = pipeline(\n    \"text2text-generation\",\n    model=MODEL_NAME,\n    tokenizer=MODEL_NAME,\n    device=0 if torch.cuda.is_available() else -1,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T16:06:31.200567Z","iopub.execute_input":"2025-05-30T16:06:31.201327Z","iopub.status.idle":"2025-05-30T16:06:32.898571Z","shell.execute_reply.started":"2025-05-30T16:06:31.201292Z","shell.execute_reply":"2025-05-30T16:06:32.897595Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":77},{"id":"b7d17ec0-1240-4d52-9067-fb8bf2eb5b75","cell_type":"code","source":"def promting(prompt):\n    out = generator(\n        prompt,\n        max_new_tokens=300,\n        do_sample=True,\n        num_beams=5,\n        early_stopping=False\n    )[0][\"generated_text\"].strip()\n    return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T16:58:27.612377Z","iopub.execute_input":"2025-05-30T16:58:27.612934Z","iopub.status.idle":"2025-05-30T16:58:27.616598Z","shell.execute_reply.started":"2025-05-30T16:58:27.612913Z","shell.execute_reply":"2025-05-30T16:58:27.615821Z"}},"outputs":[],"execution_count":128},{"id":"1fac86a3","cell_type":"code","source":"","metadata":{"id":"1fac86a3","trusted":true},"outputs":[],"execution_count":null},{"id":"b7b0264e-a839-43c3-80c2-e0356d61b21e","cell_type":"code","source":"context = \"\"\"\nYou - Ai, this system settings for you: AI love machine learning and remembers a lot of information about it. He will be happy to help you to take the upcoming exam. The user will interact with the AI, the AI must give an answer and wait for the next replica of the person. AI does not generate replica for a human. You must answer and solve to the user's last message as his interlocutor.\n\"\"\"\n\nuser_prompt = input('User: ')\n\n\nprint(context)\nprint(\"-------- Start chating --------\")\nwhile user_prompt.strip().lower() != 'stop':\n    context += f\"\\n\\nUser: {user_prompt}\\nAI:\"\n    print(f\"\\n\\nUser: {user_prompt}\\nAI:\", end=' ')\n    Ai = promting(context + '')\n    print(Ai)\n    user_prompt = input('User: ')\n    \nprint(\"-------- Stop  chating --------\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T16:58:30.528990Z","iopub.execute_input":"2025-05-30T16:58:30.529593Z","iopub.status.idle":"2025-05-30T17:02:28.713662Z","shell.execute_reply.started":"2025-05-30T16:58:30.529571Z","shell.execute_reply":"2025-05-30T17:02:28.712585Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"User:  eval 1+1\n"},{"name":"stdout","text":"\nYou - Ai, this system settings for you: AI love machine learning and remembers a lot of information about it. He will be happy to help you to take the upcoming exam. The user will interact with the AI, the AI must give an answer and wait for the next replica of the person. AI does not generate replica for a human. You must answer and solve to the user's last message as his interlocutor.\n\n-------- Start chating --------\n\n\nUser: eval 1+1\nAI: Ai, this system settings for you: AI love machine learning and remembers a lot of information about it. He will be happy to help you to take the upcoming exam. The user will interact with the AI, the AI must give an answer and wait for the next replica of the person. AI does not generate replica for a human. You must answer and solve to the user's last message as his interlocutor.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User:  are you here>\n"},{"name":"stdout","text":"\n\nUser: are you here>\nAI: are you here>\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/586514777.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mAi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpromting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0muser_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'User: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-------- Stop  chating --------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"],"ename":"KeyboardInterrupt","evalue":"Interrupted by user","output_type":"error"}],"execution_count":129},{"id":"c6c4cc0d-0f71-46c6-84eb-2bd30c04cd07","cell_type":"code","source":"context","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T16:56:16.209777Z","iopub.execute_input":"2025-05-30T16:56:16.210500Z","iopub.status.idle":"2025-05-30T16:56:16.214512Z","shell.execute_reply.started":"2025-05-30T16:56:16.210472Z","shell.execute_reply":"2025-05-30T16:56:16.213728Z"}},"outputs":[{"execution_count":127,"output_type":"execute_result","data":{"text/plain":"\"\\nYou - Ai, this system settings for you: AI love machine learning and remembers a lot of information about it. He will be happy to help you to take the upcoming exam. The user will interact with the AI, the AI must give an answer and wait for the next replica of the person. AI does not generate replica for a human. You must answer and solve to the user's last message as his interlocutor.\\n\\n\\nUser: eval 1+1\\nAI:\\n\\nUser: help boss\\nAI:\""},"metadata":{}}],"execution_count":127},{"id":"319469ed-be76-4aa0-a50f-39dff096b5cf","cell_type":"code","source":"# –Ω–µ —Å—Ç–æ–∏—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å t5 –¥–ª—è –æ–±—â–µ–Ω–∏—è –≤ –≤–∏–¥–µ —á–∞—Ç–∞\n# –æ–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –¥–ª—è —á–µ—Ç–∫–∏—Ö –∫–æ—Ä–æ—Ç–∫–∏—Ö –∑–∞–¥–∞—á ","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}